{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence GAN from char-rnn\n",
    "This is a character-level language model using recurrent neural networks based Sequence GAN (SeqGAN).\n",
    "SeqGAN was proposed to cover discrete sequence data.\n",
    "In this assignment, you will implement SeqGAN with shakespeare data used in assignment 3.\n",
    "\n",
    "Original blog post & code:\n",
    "https://github.com/LantaoYu/SeqGAN\n",
    "\n",
    "That said, you are allowed to copy paste the codes from the original repo with an additional effort to apply it to our data.\n",
    "HOWEVER, try to implement the model yourself first, and consider the original source code as a last resort.\n",
    "You will learn a lot while wrapping around your head during the implementation. And you will understand more clearly in a code level.\n",
    "\n",
    "### AND MOST IMPORTANTLY, IF YOU JUST BLINDLY COPY PASTE THE CODE, YOU SHALL RUIN YOUR EXAM.\n",
    "### The exam is designed to be solvable for students that actually have written the code themselves.\n",
    "At least strictly re-type the codes from the original repo line-by-line, and understand what each line means thoroughly.\n",
    "\n",
    "## YOU HAVE BEEN WARNED.\n",
    "\n",
    "Now proceed to the code. You may use textloader in previous assingment or not. You can freely create another python files (\\*.py) and then import them. Following codes can be modified as you want. Just make sure that SeqGAN training works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "# ipython magic function for limiting the gpu to be seen for tensorflow\n",
    "# if you have just 1 GPU, specify the value to 0\n",
    "# if you have multiple GPUs (nut) and want to specify which GPU to use, specify this value to 0 or 1 or etc.\n",
    "%env CUDA_DEVICE_ORDER = PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES = 2\n",
    "# load a bunch of libraries\n",
    "#from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import legacy_seq2seq\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from six import text_type\n",
    "import sys\n",
    "\n",
    "# this module is from the .py file of this folder\n",
    "# it handles loading texts to digits (aka. tokens) which are recognizable for the model\n",
    "from utils import TextLoader\n",
    "\n",
    "# for TensorFlow vram efficiency: if this is not specified, the model hogs all the VRAM even if it's not necessary\n",
    "# bad & greedy TF! but it has a reason for this design choice FWIW, try googling it if interested\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "data_dir = 'data/tinyshakespeare'\n",
    "seq_length = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the generator class and any other methods required for the generator class. You may define such methods in other python files (ex : utils.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the Model.py, there is the generator method.\n",
    "import model\n",
    "#We refered and copied coded from the original blog post & code(https://github.com/ofirnachum)\n",
    "#Also, we applied the our things to the reference code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the discriminator class and any other methods required for the discriminator class. You may define such methods in other python files (ex : utils.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the Model.py, there is the discriminator, roll out, and other methods that helps to implement.\n",
    "#We refered and copied coded from the original blog post & code(https://github.com/ofirnachum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need any other class or method, use below blanks. You may insert or delete blanks as many you want. Of course, you may define them in other python files and then import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num words 37\n",
      "stream length 200018\n",
      "distinct 3-grams 5193\n",
      "training\n",
      " \n",
      "epoch 0\n",
      "running 10000 iterations with 1 g steps and 2 d steps\n",
      "of the g steps, 1.00 will be supervised\n",
      ">>>> correct generations (supervised, unsupervised): 0.0012998700129987 0.0\n",
      "None\n",
      " \n",
      " \n",
      "epoch 1\n",
      "running 10000 iterations with 1 g steps and 2 d steps\n",
      "of the g steps, 0.98 will be supervised\n",
      ">>>> correct generations (supervised, unsupervised): 0.003875968992248062 0.05555555555555555\n",
      "[' ', 'f', 'o', ' ', 's', 'e', \"'\", 's', 'o', 'b', 'u', ' ', 'o', 'n', 'd', ' ', 'o', 'm', ' ', 'o']\n",
      "[\" fo se'sobu ond om o\"]\n",
      " \n",
      "epoch 2\n",
      "running 10000 iterations with 1 g steps and 2 d steps\n",
      "of the g steps, 0.96 will be supervised\n",
      ">>>> correct generations (supervised, unsupervised): 0.004789670970428988 0.09547738693467336\n",
      "[' ', 'h', 'l', 'e', 't', 'a', 'r', ',', ' ', 'd', 'o', 'r', 'd', ' ', 'k', 'o', 's', 'e', 'm', 'a']\n",
      "[' hletar, dord kosema']\n",
      " \n",
      "epoch 3\n",
      "running 10000 iterations with 1 g steps and 2 d steps\n",
      "of the g steps, 0.94 will be supervised\n",
      ">>>> correct generations (supervised, unsupervised): 0.0037253858435337944 0.11367380560131796\n",
      "['f', ' ', 'i', 'n', 'd', 't', ' ', 't', 'i', 'r', 'g', 'e', 'r', ' ', 't', 'h', 'e', ' ', 't', 'h']\n",
      "['f indt tirger the th']\n",
      " \n",
      "epoch 4\n",
      "running 10000 iterations with 1 g steps and 2 d steps\n",
      "of the g steps, 0.92 will be supervised\n",
      ">>>> correct generations (supervised, unsupervised): 0.005212292322727767 0.1424968474148802\n",
      "['o', 'l', 'd', ',', '.', ' ', 'a', ' ', 's', 'l', 'o', 'o', 'u', 'r', ':', ' ', 'b', 'o', 'u', 'm']\n",
      "['old,. a sloour: boum']\n",
      " \n",
      "epoch 5\n",
      "running 10000 iterations with 1 g steps and 2 d steps\n",
      "of the g steps, 0.90 will be supervised\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import codecs\n",
    "\n",
    "__doc__ = \"\"\"Char-based Seq-GAN on data from a book.\"\"\"\n",
    "\n",
    "\n",
    "import train\n",
    "\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import subprocess\n",
    "import gzip\n",
    "\n",
    "EMB_DIM = 20\n",
    "HIDDEN_DIM = 25\n",
    "SEQ_LENGTH = 20\n",
    "START_TOKEN = 0\n",
    "\n",
    "EPOCH_ITER = 10000\n",
    "CURRICULUM_RATE = 0.02  # how quickly to move from supervised training to unsupervised\n",
    "TRAIN_ITER = 1000000  # generator/discriminator alternating\n",
    "D_STEPS = 2  # how many times to train the discriminator per generator step\n",
    "SEED = 88\n",
    "\n",
    "DATA_FILE = 'data/tinyshakespeare/input.txt'\n",
    "\n",
    "\n",
    "def tokenize(s):\n",
    "    return [c for c in ' '.join(s.split())]\n",
    "\n",
    "\n",
    "def get_data(download=not os.path.exists(DATA_FILE)):\n",
    "    token_stream = []\n",
    "    is_gzip = False\n",
    "    try:\n",
    "        open(DATA_FILE).read(2)\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"HERE\")\n",
    "    with gzip.open(DATA_FILE) if is_gzip else codecs.open(DATA_FILE, 'r', 'utf-8',errors='ignore') as f:\n",
    "        for line in f:\n",
    "            line = line if not is_gzip else line.decode('utf-8')\n",
    "            if (\"Even to the court, the heart, to the seat o' the brain;\" in line or token_stream) and line.strip():\n",
    "                token_stream.extend(tokenize(line.strip().lower()))\n",
    "                token_stream.append(' ')\n",
    "            if len(token_stream) > 10000 * SEQ_LENGTH:  # enough data\n",
    "                break\n",
    "\n",
    "    return token_stream\n",
    "\n",
    "\n",
    "class BookGRU(model.GRU):\n",
    "\n",
    "    def d_optimizer(self, *args, **kwargs):\n",
    "        return tf.train.AdamOptimizer()  # ignore learning rate\n",
    "\n",
    "    def g_optimizer(self, *args, **kwargs):\n",
    "        return tf.train.AdamOptimizer()  # ignore learning rate\n",
    "\n",
    "\n",
    "def get_trainable_model(num_emb):\n",
    "    return BookGRU(\n",
    "        num_emb, EMB_DIM, HIDDEN_DIM,\n",
    "        SEQ_LENGTH, START_TOKEN)\n",
    "\n",
    "\n",
    "def get_random_sequence(token_stream, word2idx):\n",
    "    \"\"\"Returns random subsequence.\"\"\"\n",
    "    start_idx = random.randint(0, len(token_stream) - SEQ_LENGTH)\n",
    "    return [word2idx[tok] for tok in token_stream[start_idx:start_idx + SEQ_LENGTH]]\n",
    "\n",
    "\n",
    "def verify_sequence(three_grams, seq):\n",
    "    \"\"\"Not a true verification; only checks 3-grams.\"\"\"\n",
    "    for i in range(len(seq) - 3):\n",
    "        if tuple(seq[i:i + 3]) not in three_grams:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    token_stream = get_data()\n",
    "    assert START_TOKEN == 0\n",
    "    words = ['_START'] + list(set(token_stream))\n",
    "    word2idx = dict((word, i) for i, word in enumerate(words))\n",
    "    num_words = len(words)\n",
    "    three_grams = dict((tuple(word2idx[w] for w in token_stream[i:i + 3]), True)\n",
    "                       for i in range(len(token_stream) - 3))\n",
    "    extends_words = []\n",
    "    print('num words', num_words)\n",
    "    print('stream length', len(token_stream))\n",
    "    print('distinct 3-grams', len(three_grams))\n",
    "\n",
    "    trainable_model = get_trainable_model(num_words)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print('training')\n",
    "    for epoch in range(TRAIN_ITER // EPOCH_ITER):\n",
    "        print(\" \")\n",
    "        print('epoch', epoch)\n",
    "        proportion_supervised = max(0.0, 1.0 - CURRICULUM_RATE * epoch)\n",
    "        train.train_epoch(\n",
    "            sess, trainable_model, EPOCH_ITER,\n",
    "            proportion_supervised=proportion_supervised,\n",
    "            g_steps=1, d_steps=D_STEPS,\n",
    "            next_sequence=lambda: get_random_sequence(token_stream, word2idx),\n",
    "            verify_sequence=lambda seq: verify_sequence(three_grams, seq),\n",
    "            words=words)\n",
    "    #print('words will be like ', words)\n",
    "    #print(*extends_words, sep = \"\\n\") \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the main code processing the train. You should show at least 16 generated text sequences at the end of the training. We will judge your progress with your final generated result. Be sure to pretrain the generator using supervised frame before training the model with SeqGAN framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
