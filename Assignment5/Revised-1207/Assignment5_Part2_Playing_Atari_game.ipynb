{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2177.003100 Deep Learning <br>Assignment #5 Part 2: Playing Atari games using a A3C agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (C) Data Science Laboratory, Seoul National University. This material is for educational uses only. Some contents are based on the material provided by other paper/book authors and may be copyrighted by them. Written by Hyemi Jang, November 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will make an agent to play Atari games. Your agent is based on A3C.<br>\n",
    "In this notebook, you will implement your A3C codes to learn how to play Atari games according to the reference paper [1]. <br>\n",
    "You need to follow the instructions to implement the given classes.\n",
    "\n",
    "There is a bade code of A3C in TensorFlow https://github.com/openai/universe-starter-agent This iPython notebook is basically a copypasta of this repo.\n",
    "\n",
    "That said, you are allowed to copy paste the codes from the original repo. HOWEVER, try to implement the model yourself first, and consider the original source code as a last resort. You will learn a lot while wrapping around your head during the implementation. And you will understand nuts and bolts of RNNs more clearly in a code level.\n",
    "\n",
    "1. [Play](#Play) ( 50 points )\n",
    "\n",
    "**Note**: certain details are missing or ambiguous on purpose, in order to test your knowledge on the related materials. However, if you really feel that something essential is missing and cannot proceed to the next step, then contact the teaching staff with clear description of your problem.\n",
    "\n",
    "### Submitting your work:\n",
    "<font color=red>**DO NOT clear the final outputs**</font> so that TAs can grade both your code and results.  \n",
    "Once you have done **two parts of the assignment**, run the *CollectSubmission.sh* script with your **Team number** as input argument. <br>\n",
    "This will produce a zipped file called *[Your team number].tar.gz*. Please submit this file on ETL. &nbsp;&nbsp; (Usage: ./*CollectSubmission.sh* &nbsp; Team_#)\n",
    "\n",
    "### Some helpful references for assignment #5:\n",
    "- [1] Mnih, Volodymyr, et al. \"Asynchronous methods for deep reinforcement learning.\" International conference on machine learning. 2016.\n",
    "- [2] OpenAI GYM website [[link]](https://gym.openai.com/envs) and [[git]](https://github.com/openai/gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import sys; sys.argv=['']\n",
    "#del sys\n",
    "from six.moves import shlex_quote\n",
    "import tensorflow as tf\n",
    "import cv2 # uncomment to render game screens\n",
    "import gym\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)\n",
    "print(gym.spec(\"Pong-v0\").tags.get('atari', False))\n",
    "print(gym.spec(\"PongDeterministic-v3\").tags.get('flashgames', False))\n",
    "import distutils.version\n",
    "use_tf12_api = distutils.version.LooseVersion(tf.VERSION) >= distutils.version.LooseVersion('0.12.0')\n",
    "print (use_tf12_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make command for calling workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_cmd(session, name, cmd, logdir, shell):\n",
    "    if isinstance(cmd, (list, tuple)):\n",
    "        cmd = \" \".join(shlex_quote(str(v)) for v in cmd)\n",
    "    return name, \"tmux send-keys -t {}:{} {} Enter\".format(session, name, shlex_quote(cmd))\n",
    "   \n",
    "\n",
    "def create_commands(session, num_workers, remotes, env_id, logdir, test=False, shell='bash',visualise=False):\n",
    "    # for launching the TF workers and for launching tensorboard\n",
    "    base_cmd = [\n",
    "        'CUDA_VISIBLE_DEVICES=',\n",
    "        sys.executable, 'worker.py',\n",
    "        '--log-dir', logdir,\n",
    "        '--env-id', env_id,\n",
    "        '--num-workers', str(num_workers)]\n",
    "\n",
    "    if visualise:\n",
    "        base_cmd += ['--visualise']\n",
    "    \n",
    "    if test:\n",
    "        base_cmd += ['--test']\n",
    "        \n",
    "    if remotes is None:\n",
    "        remotes = [\"1\"] * num_workers\n",
    "    else:\n",
    "        remotes = remotes.split(',')\n",
    "        assert len(remotes) == num_workers\n",
    "\n",
    "    cmds_map = [new_cmd(session, \"ps\", base_cmd + [\"--job-name\", \"ps\"], logdir, shell)]\n",
    "    for i in range(num_workers):\n",
    "        cmds_map += [new_cmd(session,\n",
    "            \"w-%d\" % i, base_cmd + [\"--job-name\", \"worker\", \"--task\", str(i), \"--remotes\", remotes[i]], logdir, shell)]\n",
    "\n",
    "    cmds_map += [new_cmd(session, \"tb\", [\"tensorboard\", \"--logdir\", logdir, \"--port\", \"12345\"], logdir, shell)]\n",
    "    \n",
    "    cmds_map += [new_cmd(session, \"htop\", [\"htop\"], logdir, shell)]\n",
    "\n",
    "    windows = [v[0] for v in cmds_map]\n",
    "\n",
    "    notes = []\n",
    "    cmds = [\n",
    "        \"mkdir -p {}\".format(logdir),\n",
    "        \"echo {} {} > {}/cmd.sh\".format(sys.executable, ' '.join([shlex_quote(arg) for arg in sys.argv if arg != '-n']), logdir),\n",
    "    ]\n",
    "    \n",
    "    notes += [\"Use `tmux attach -t {}` to watch process output\".format(session)]\n",
    "    notes += [\"Use `tmux kill-session -t {}` to kill the job\".format(session)]\n",
    "    notes += [\"Point your browser to http://localhost:12345 to see Tensorboard\"]\n",
    "\n",
    "    cmds += [\n",
    "    \"kill $( lsof -i:12345 -t ) > /dev/null 2>&1\",  # kill any process using tensorboard's port\n",
    "    \"kill $( lsof -i:12222-{} -t ) > /dev/null 2>&1\".format(num_workers+12222), # kill any processes using ps / worker ports\n",
    "    \"tmux kill-session -t {}\".format(session),\n",
    "    \"tmux new-session -s {} -n {} -d {}\".format(session, windows[0], shell)\n",
    "    ]\n",
    "    for w in windows[1:]:\n",
    "        cmds += [\"tmux new-window -t {} -n {} {}\".format(session, w, shell)]\n",
    "    cmds += [\"sleep 1\"]\n",
    "    for window, cmd in cmds_map:\n",
    "        cmds += [cmd]\n",
    "\n",
    "    return cmds, notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"train\"></a>2. Train your agent\n",
    "\n",
    "Now, we train an agent to play Pong-v0. Pong-v0 is generally the easiest game for learning.<br>\n",
    "The maximum value of total reward which can be aquired from one episdoe is 21 (when your agent wins with 21:0).<br>\n",
    "You have to implement the file a3c.py, envs.py, model.py, worker.py. <br>\n",
    "Attach the training process to the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--visualise'], dest='visualise', nargs=0, const=True, default=False, type=None, choices=None, help='Visualise the gym environment by running env.render() between each timestep', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Run commands\")\n",
    "parser.add_argument('-w', '--num-workers', default=10, type=int,\n",
    "                    help=\"Number of workers\")\n",
    "parser.add_argument('-r', '--remotes', default=None,\n",
    "                    help='The address of pre-existing VNC servers and '\n",
    "                         'rewarders to use (e.g. -r vnc://localhost:5900+15900,vnc://localhost:5901+15901).')\n",
    "parser.add_argument('-e', '--env-id', type=str, default='Pong-v0',\n",
    "                    help=\"Environment id\")\n",
    "parser.add_argument('-l', '--log-dir', type=str, default=\"./pong\",\n",
    "                    help=\"Log directory path\")\n",
    "parser.add_argument('--test',action= 'store_true')\n",
    "# Add visualise tag\n",
    "parser.add_argument('--visualise', action='store_true',\n",
    "                    help=\"Visualise the gym environment by running env.render() between each timestep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(env_id='Pong-v0', log_dir='./pong', num_workers=10, remotes=None, test=False, visualise=False)\n",
      "Executing the following commands:\n",
      "mkdir -p ./pong\n",
      "echo /home/bivtt4/anaconda3/bin/python '' > ./pong/cmd.sh\n",
      "kill $( lsof -i:12345 -t ) > /dev/null 2>&1\n",
      "kill $( lsof -i:12222-12232 -t ) > /dev/null 2>&1\n",
      "tmux kill-session -t a3c\n",
      "tmux new-session -s a3c -n ps -d bash\n",
      "tmux new-window -t a3c -n w-0 bash\n",
      "tmux new-window -t a3c -n w-1 bash\n",
      "tmux new-window -t a3c -n w-2 bash\n",
      "tmux new-window -t a3c -n w-3 bash\n",
      "tmux new-window -t a3c -n w-4 bash\n",
      "tmux new-window -t a3c -n w-5 bash\n",
      "tmux new-window -t a3c -n w-6 bash\n",
      "tmux new-window -t a3c -n w-7 bash\n",
      "tmux new-window -t a3c -n w-8 bash\n",
      "tmux new-window -t a3c -n w-9 bash\n",
      "tmux new-window -t a3c -n tb bash\n",
      "tmux new-window -t a3c -n htop bash\n",
      "sleep 1\n",
      "tmux send-keys -t a3c:ps 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name ps' Enter\n",
      "tmux send-keys -t a3c:w-0 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 0 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:w-1 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 1 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:w-2 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 2 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:w-3 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 3 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:w-4 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 4 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:w-5 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 5 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:w-6 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 6 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:w-7 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 7 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:w-8 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 8 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:w-9 'CUDA_VISIBLE_DEVICES= /home/bivtt4/anaconda3/bin/python worker.py --log-dir ./pong --env-id Pong-v0 --num-workers 10 --job-name worker --task 9 --remotes 1' Enter\n",
      "tmux send-keys -t a3c:tb 'tensorboard --logdir ./pong --port 12345' Enter\n",
      "tmux send-keys -t a3c:htop htop Enter\n",
      "\n",
      "Use `tmux attach -t a3c` to watch process output\n",
      "Use `tmux kill-session -t a3c` to kill the job\n",
      "Point your browser to http://localhost:12345 to see Tensorboard\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "print(args)\n",
    "cmds, notes = create_commands(\"a3c\", args.num_workers, args.remotes, args.env_id, args.log_dir, args.test, visualise=args.visualise)\n",
    "#print(cmds)\n",
    "#print(notes)\n",
    "print(\"Executing the following commands:\")\n",
    "print(\"\\n\".join(cmds))\n",
    "print(\"\") \n",
    "os.environ[\"TMUX\"] = \"\"\n",
    "os.system(\"\\n\".join(cmds))\n",
    "print('\\n'.join(notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"train\"></a>3. Test your agent\n",
    "Now, we test your agent and calculate an average reward of 20 episodes.\n",
    "- -21 <= average reward < -10 : you can get 0 points\n",
    "- -10 <= average reward < 0 : you can get 10 points\n",
    "- 0 <= average reward < 10 : you can get 20 points\n",
    "- 10 <= average reward < 17 : you can get 30 points\n",
    "- 17 <= average reward <= 21 : you can get 50 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = parser.parse_args()\n",
    "cmds, notes = create_commands(\"a3c\", 1, args.remotes, args.env_id, args.log_dir, True, visualise=args.visualise)\n",
    "\n",
    "print(\"Executing the following commands:\")\n",
    "print(\"\\n\".join(cmds))\n",
    "print(\"\")\n",
    "os.environ[\"TMUX\"] = \"\"\n",
    "os.system(\"\\n\".join(cmds))\n",
    "print('\\n'.join(notes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
